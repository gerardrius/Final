{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import folium\n",
    "import folium.plugins\n",
    "from folium import Figure\n",
    "from folium.plugins import HeatMapWithTime\n",
    "\n",
    "# For real distance\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "\n",
    "import src.cleaning as cleaning\n",
    "import src.visualizations as vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample to test functions:\n",
    "apr_14 = pd.read_csv('../../../Desktop/final_project_data/2014/2014-04 - Citi Bike trip data.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. CLEANING PROCESS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "apr_14 = cleaning.rename_columns(apr_14)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Straight line Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "apr_14 = cleaning.trip_distance(apr_14)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hour: start_hour & end_hour (same function, 2 columns)\n",
    "\n",
    "- Integer value for the hour, e.g. 12, 18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "apr_14 = cleaning.get_hour (apr_14)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date: trip_date\n",
    "- time series date format for date, including year, month and day, and excluding hour, minute and second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "apr_14 = cleaning.get_date (apr_14)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting: started_at and ended_at in datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "apr_14 = cleaning.datetime_format (apr_14)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Month, weekday, weekend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "apr_14 = cleaning.get_categorical_date (apr_14)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaned and enriched dataframe to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "apr_14.to_csv('data/april_2014.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "april_14 = pd.read_csv('data/april_2014.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Street Map: real_distance\n",
    "### Function to create subdataframes and save them as csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in Collab\n",
    "\n",
    "# cleaning.dataframe_split (df, n): Splits the dataframe in n subdataframes to make it more processable.\n",
    "# cleaning.get_real_distance (df): uses osmnx and networkx to compute the shortest available path distance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rideable_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer from 2022 datasets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trip_cost ()\n",
    "\n",
    "¡You need to get bike type before!\n",
    "\n",
    "- float $ value in function of rideable_type, duration and member_casual.\n",
    "\n",
    "Subscriber\n",
    "- Classic.\n",
    "If trip_duration < 45*60, cost = 0\n",
    "Elif trip_duration > 45*60, cost = (trip_duration - 45 * 60) / 60 * 0.17\n",
    "\n",
    "- Electric\n",
    "If trip_duration =< 45*60: cost = trip_duration / 60 * 0.17, limit 3.\n",
    "If trip_duration > 45*60: cost = 3 + (trip_duration - 45 * 60) / 60 * 0.17\n",
    "\n",
    "Casual\n",
    "- Single trip \n",
    "    - Casual & - Electric\n",
    "    If trip_duration <= 30*60 -> 4.49\n",
    "    Elif trip_duration > 30 * 60 -> 4.49 + (trip_duration - 30 * 60) / 60 * 0.26\n",
    "\n",
    "- Day Pass\n",
    "    - Casual \n",
    "    - Electric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to know rideable type."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Station non-bike trips balance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bike Route (not by human usage):\n",
    "\n",
    "All bikes journey function includes bike route function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bikes_journey_list = cleaning.all_bikes_journey (april_14)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non user trip mobility dictionary and information:\n",
    "\n",
    "### Three functions that enrich a dictionary containing all info regarding mobility from one station to another through trucks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_transfers_dictionary = cleaning.non_trip_mobility_dict (apr_14)\n",
    "stations_transfers_dictionary = cleaning.transportations (stations_transfers_dictionary, all_bikes_journey_list)\n",
    "stations_transfers_dictionary = cleaning.station_balance (stations_transfers_dictionary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truck trips\n",
    "\n",
    "Record all bike movements not attributable to user trips.\n",
    "- Bike ID\n",
    "- Date range\n",
    "- Transported from\n",
    "- Transported to\n",
    "\n",
    "Sort by date, group by station.\n",
    "\n",
    "### All transfers use single bike truck transfers function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_transfers = cleaning.all_transfers (april_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_transfers = cleaning.datetime_format_trucks (total_transfers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_transfers.to_csv('data/truck_transfers.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions defined in source folder, deployed in streamlit app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly distribution by day:\n",
    "def hourly_dist (df, day):\n",
    "    test_map_viz = df[['start_hour', 'started_at', 'bike_id', 'start_lat', 'start_lng', 'weekday']]\n",
    "    test_map_viz = test_map_viz[test_map_viz['weekday'] == day]\n",
    "\n",
    "    lat_lng_list = []\n",
    "    for i in range(24):\n",
    "        temp=[]\n",
    "        for index, row in test_map_viz[test_map_viz['start_hour'] == i].iterrows():\n",
    "            temp.append([row['start_lat'],row['start_lng']])\n",
    "        lat_lng_list.append(temp)\n",
    "\n",
    "    figure1 = Figure(width=850,height=550)\n",
    "    new_york1 = folium.Map(location=[40.712776, -74.005974],zoom_start=12)\n",
    "\n",
    "    figure1.add_child(new_york1)\n",
    "    folium.TileLayer('cartodbpositron').add_to(new_york1)\n",
    "    gradient = {.33: 'white', .66: 'lightblue', 1: 'blue'}\n",
    "\n",
    "    HeatMapWithTime(lat_lng_list, radius=5, auto_play=True, position='bottomright', gradient=gradient).add_to(new_york1)\n",
    "\n",
    "    return figure1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_dist (april_14, 'Monday')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Your Trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trucks = pd.read_csv('data/truck_transfers.csv')\n",
    "april = pd.read_csv('data/april_2014.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gerardrius/Ironhack/projects/Final/src/cleaning.py:452: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype=datetime64[ns])\n",
      "  result_df = pd.DataFrame({'last_end': last_end, 'ended_at': etime, 'next_start': next_start, 'started_at': stime})\n",
      "/Users/gerardrius/Ironhack/projects/Final/src/cleaning.py:452: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype=datetime64[ns])\n",
      "  result_df = pd.DataFrame({'last_end': last_end, 'ended_at': etime, 'next_start': next_start, 'started_at': stime})\n",
      "/Users/gerardrius/Ironhack/projects/Final/src/cleaning.py:452: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype=datetime64[ns])\n",
      "  result_df = pd.DataFrame({'last_end': last_end, 'ended_at': etime, 'next_start': next_start, 'started_at': stime})\n",
      "/Users/gerardrius/Ironhack/projects/Final/src/cleaning.py:452: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype=datetime64[ns])\n",
      "  result_df = pd.DataFrame({'last_end': last_end, 'ended_at': etime, 'next_start': next_start, 'started_at': stime})\n",
      "/Users/gerardrius/Ironhack/projects/Final/src/cleaning.py:452: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype=datetime64[ns])\n",
      "  result_df = pd.DataFrame({'last_end': last_end, 'ended_at': etime, 'next_start': next_start, 'started_at': stime})\n",
      "/Users/gerardrius/Ironhack/projects/Final/src/cleaning.py:452: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype=datetime64[ns])\n",
      "  result_df = pd.DataFrame({'last_end': last_end, 'ended_at': etime, 'next_start': next_start, 'started_at': stime})\n",
      "/Users/gerardrius/Ironhack/projects/Final/src/cleaning.py:452: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype=datetime64[ns])\n",
      "  result_df = pd.DataFrame({'last_end': last_end, 'ended_at': etime, 'next_start': next_start, 'started_at': stime})\n"
     ]
    }
   ],
   "source": [
    "ALL_TRIPS = cleaning.concat_all_bike_trips (april)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_TRIPS.to_csv('data/all_trips.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.read_csv('data/all_trips.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_end</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>next_start</th>\n",
       "      <th>started_at</th>\n",
       "      <th>time_difference</th>\n",
       "      <th>bike_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>2014-04-01 00:09:25.000</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>2014-04-01 07:41:30.000</td>\n",
       "      <td>0 days 07:32:05</td>\n",
       "      <td>21062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>224.0</td>\n",
       "      <td>2014-04-01 07:48:08.000</td>\n",
       "      <td>224.0</td>\n",
       "      <td>2014-04-01 08:54:32.000</td>\n",
       "      <td>0 days 01:06:24</td>\n",
       "      <td>21062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>360.0</td>\n",
       "      <td>2014-04-01 08:58:20.000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>2014-04-01 15:03:40.800</td>\n",
       "      <td>0 days 06:05:20.800000</td>\n",
       "      <td>21062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>306.0</td>\n",
       "      <td>2014-04-02 09:19:43.200</td>\n",
       "      <td>306.0</td>\n",
       "      <td>2014-04-02 15:25:04.000</td>\n",
       "      <td>0 days 06:05:20.800000</td>\n",
       "      <td>21062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>147.0</td>\n",
       "      <td>2014-04-02 15:32:24.000</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2014-04-02 17:22:38.000</td>\n",
       "      <td>0 days 01:50:14</td>\n",
       "      <td>21062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>151.0</td>\n",
       "      <td>2014-04-10 18:14:27.000</td>\n",
       "      <td>151.0</td>\n",
       "      <td>2014-04-10 18:14:53.000</td>\n",
       "      <td>0 days 00:00:26</td>\n",
       "      <td>20914.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>531.0</td>\n",
       "      <td>2014-04-10 18:20:36.000</td>\n",
       "      <td>531.0</td>\n",
       "      <td>2014-04-10 18:59:16.000</td>\n",
       "      <td>0 days 00:38:40</td>\n",
       "      <td>20914.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>445.0</td>\n",
       "      <td>2014-04-10 19:07:10.000</td>\n",
       "      <td>445.0</td>\n",
       "      <td>2014-04-10 21:20:33.800</td>\n",
       "      <td>0 days 02:13:23.800000</td>\n",
       "      <td>20914.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>519.0</td>\n",
       "      <td>2014-04-11 04:00:45.200</td>\n",
       "      <td>519.0</td>\n",
       "      <td>2014-04-11 06:14:09.000</td>\n",
       "      <td>0 days 02:13:23.800000</td>\n",
       "      <td>20914.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>405.0</td>\n",
       "      <td>2014-04-11 06:31:26.000</td>\n",
       "      <td>405.0</td>\n",
       "      <td>2014-04-12 12:32:53.000</td>\n",
       "      <td>1 days 06:01:27</td>\n",
       "      <td>20914.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     last_end                 ended_at  next_start               started_at  \\\n",
       "0      2008.0  2014-04-01 00:09:25.000      2008.0  2014-04-01 07:41:30.000   \n",
       "1       224.0  2014-04-01 07:48:08.000       224.0  2014-04-01 08:54:32.000   \n",
       "2       360.0  2014-04-01 08:58:20.000       360.0  2014-04-01 15:03:40.800   \n",
       "3       306.0  2014-04-02 09:19:43.200       306.0  2014-04-02 15:25:04.000   \n",
       "4       147.0  2014-04-02 15:32:24.000       147.0  2014-04-02 17:22:38.000   \n",
       "..        ...                      ...         ...                      ...   \n",
       "495     151.0  2014-04-10 18:14:27.000       151.0  2014-04-10 18:14:53.000   \n",
       "496     531.0  2014-04-10 18:20:36.000       531.0  2014-04-10 18:59:16.000   \n",
       "497     445.0  2014-04-10 19:07:10.000       445.0  2014-04-10 21:20:33.800   \n",
       "498     519.0  2014-04-11 04:00:45.200       519.0  2014-04-11 06:14:09.000   \n",
       "499     405.0  2014-04-11 06:31:26.000       405.0  2014-04-12 12:32:53.000   \n",
       "\n",
       "            time_difference  bike_id  \n",
       "0           0 days 07:32:05  21062.0  \n",
       "1           0 days 01:06:24  21062.0  \n",
       "2    0 days 06:05:20.800000  21062.0  \n",
       "3    0 days 06:05:20.800000  21062.0  \n",
       "4           0 days 01:50:14  21062.0  \n",
       "..                      ...      ...  \n",
       "495         0 days 00:00:26  20914.0  \n",
       "496         0 days 00:38:40  20914.0  \n",
       "497  0 days 02:13:23.800000  20914.0  \n",
       "498  0 days 02:13:23.800000  20914.0  \n",
       "499         1 days 06:01:27  20914.0  \n",
       "\n",
       "[500 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.iloc[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "519.0     True\n",
       "521.0     True\n",
       "497.0     True\n",
       "293.0     True\n",
       "435.0     True\n",
       "          ... \n",
       "119.0     True\n",
       "372.0     True\n",
       "431.0     True\n",
       "2005.0    True\n",
       "321.0     True\n",
       "Length: 330, dtype: bool"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_TRIPS.last_end.value_counts() == ALL_TRIPS.next_start.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = []\n",
    "for i in range(1,10):\n",
    "    date_range.append(f'2014-04-0{i}')\n",
    "\n",
    "for i in range(10,31):\n",
    "    date_range.append(f'2014-04-{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def station_max_min_differences (df, times):\n",
    "    # time to datetime format\n",
    "    differences = []\n",
    "\n",
    "    for date in times:\n",
    "        date_time_obj = datetime.datetime.strptime(date, '%Y-%m-%d')\n",
    "\n",
    "        ends = df[df['ended_at'] <= date_time_obj].last_end.value_counts().to_frame().reset_index().rename(columns = {'index': 'end_id', 'last_end': 'counts'})\n",
    "        starts = df[df['started_at'] <= date_time_obj].next_start.value_counts().to_frame().reset_index().rename(columns = {'index': 'start_id', 'next_start': 'counts'})\n",
    "\n",
    "        try:\n",
    "            differences.append(ends.iloc[0]['counts'] - starts.iloc[0]['counts'])\n",
    "        except:\n",
    "            differences.append(0)\n",
    "\n",
    "    return differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 3.0,\n",
       " 5.0,\n",
       " 11.0,\n",
       " 27.0,\n",
       " 13.0,\n",
       " 14.0,\n",
       " 24.0,\n",
       " 20.0,\n",
       " 15.0,\n",
       " 11.0,\n",
       " 18.0,\n",
       " 21.0,\n",
       " 14.0,\n",
       " 18.0,\n",
       " 33.0,\n",
       " 23.0,\n",
       " 38.0,\n",
       " 99.0,\n",
       " 90.0,\n",
       " 118.0,\n",
       " 26.0,\n",
       " 28.0,\n",
       " 2.0,\n",
       " 15.0,\n",
       " 30.0,\n",
       " 10.0,\n",
       " 12.0,\n",
       " 5.0,\n",
       " 16.0]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_max_min_differences (ALL_TRIPS, date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def station_max_min_differences (df, time_range):\n",
    "    # time to datetime format\n",
    "    time_range_datetime = []\n",
    "    for date in time_range:\n",
    "        date_time_obj = datetime.datetime.strptime(date, '%Y-%m-%d')\n",
    "        time_range_datetime.append(date_time_obj)\n",
    "\n",
    "    differences = []\n",
    "\n",
    "    for date in time_range_datetime:\n",
    "        ends = df[df['ended_at'] <= date].last_end.value_counts().to_frame().reset_index().rename(columns = {'index': 'end_id', 'last_end': 'counts'})\n",
    "        starts = df[df['started_at'] <= date].next_start.value_counts().to_frame().reset_index().rename(columns = {'index': 'start_id', 'next_start': 'counts'})\n",
    "\n",
    "        differences.append(ends.iloc[0]['counts'] - starts.iloc[0]['counts'])\n",
    "\n",
    "    return differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84e87d28c5bed529ff86c4920d9f833c63e26dbaf53d0d7be4a47960d95f9549"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
